{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r:\\\\Projects\\\\Flight_Price_Prediction_ML\\\\Flight-Price-Prediction-ML-model\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('r:\\\\Projects\\\\Flight_Price_Prediction_ML\\\\Flight-Price-Prediction-ML-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r:\\\\Projects\\\\Flight_Price_Prediction_ML\\\\Flight-Price-Prediction-ML-model'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path:Path\n",
    "    label_encoders:dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.constants import *\n",
    "from mlProject.utils.common import read_yaml,create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__ (\n",
    "            self,\n",
    "            config_filepath = CONFIG_FILE_PATH,\n",
    "            params_filepath = PARAMS_FILE_PATH,\n",
    "            schema_filepath = SCHEMA_FILE_PATH,\n",
    "            label_encoding_filepath = LABEL_ENCODING_FILE_PATH):\n",
    "        \n",
    "            self.config = read_yaml(config_filepath)\n",
    "            self.params = read_yaml(params_filepath)\n",
    "            self.schema = read_yaml(schema_filepath)\n",
    "            self.labels = read_yaml(label_encoding_filepath)\n",
    "\n",
    "            create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        label_encoders = self.labels\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "             root_dir= config.root_dir,\n",
    "             data_path=config.data_path,\n",
    "             label_encoders = label_encoders\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mlProject import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-14 01:28:13,796: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-07-14 01:28:13,801: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-07-14 01:28:13,815: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-07-14 01:28:13,839: INFO: common: yaml file: label_encoding.yaml loaded successfully]\n",
      "[2024-07-14 01:28:13,849: INFO: common: created directory at: artifacts]\n"
     ]
    }
   ],
   "source": [
    "obj = ConfigurationManager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(obj.labels.airlines.keys())\n",
    "df = pd.read_excel('research\\\\Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vistara Premium economy'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(obj.labels.airlines.keys())\n",
    "a.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch\n"
     ]
    }
   ],
   "source": [
    "for i in list(df.Airline.unique()):\n",
    "    if i not in a:\n",
    "        print(\"Mismatch\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Match\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self,config:DataTransformationConfig):\n",
    "        self.config = config\n",
    "        \n",
    "\n",
    "    def data_transformation(self):\n",
    "        df_ = pd.read_excel(self.config.data_path)\n",
    "\n",
    "        df_ = df_.dropna()\n",
    "\n",
    "        #creating columns for month,year,day of journey\n",
    "\n",
    "        df_.Date_of_Journey = pd.to_datetime(df_.Date_of_Journey)\n",
    "        df_['Journey_month'] = df_.Date_of_Journey.dt.month\n",
    "        df_['Journey_year'] = df_.Date_of_Journey.dt.year\n",
    "        df_['Journey_day'] = df_.Date_of_Journey.dt.day\n",
    "\n",
    "\n",
    "        # creating columns for hours,min for depature and arrival time\n",
    "        df_.Dep_Time = pd.to_datetime(df_.Dep_Time)\n",
    "        df_['Dep_Time_hours'] = df_.Dep_Time.dt.hour\n",
    "        df_['Dep_Time_mins'] = df_.Dep_Time.dt.minute\n",
    "        df_.Arrival_Time = pd.to_datetime(df_.Arrival_Time)\n",
    "        df_['Arrival_Time_hours'] = df_.Arrival_Time.dt.hour\n",
    "        df_['Arrival_Time_mins'] = df_.Arrival_Time.dt.minute\n",
    "\n",
    "\n",
    "        df_ = df_.drop(['Date_of_Journey','Dep_Time','Arrival_Time'],axis=1)\n",
    "\n",
    "        def duration_hours(x):\n",
    "            if 'h' in x:\n",
    "                return int(x.split('h')[0])\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "\n",
    "        def duration_mins(x):\n",
    "            if 'h' in x and 'm' in x:\n",
    "                return int(x.split(' ')[1].split('m')[0])\n",
    "\n",
    "            elif 'm' in x:\n",
    "                return int(x.split('m')[0])\n",
    "\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "\n",
    "        df_['Duration_hours'] = df_['Duration'].apply(duration_hours)\n",
    "        df_['Duration_minutes'] = df_['Duration'].apply(duration_mins)\n",
    "\n",
    "\n",
    "        def total_mins(x):\n",
    "            total = x['Duration_hours']*60 + x['Duration_minutes']\n",
    "            return total\n",
    "\n",
    "        df_['Duration_total_minutes'] = df_.apply(total_mins,axis=1)\n",
    "\n",
    "        df_ = df_.drop('Duration',axis=1)\n",
    "\n",
    "        sources = df_.Source.unique()\n",
    "\n",
    "\n",
    "        # Applying One-Hot encoder in sources column\n",
    "        for source in sources:\n",
    "            df_['Source_'+source] = np.nan\n",
    "            df_['Source_'+source] = np.where(df_['Source']==source,1,0)\n",
    "\n",
    "\n",
    "        df_['Airline label'] = np.nan\n",
    "\n",
    "        airlines = dict(self.config.label_encoders.airlines)\n",
    "        \n",
    "        # Applying Label encoding in airline column\n",
    "        df_['Airline label'] = df_['Airline'].map(airlines)\n",
    "        df_ = df_.drop('Airline',axis=1)\n",
    "\n",
    "\n",
    "        destinations = dict(self.config.label_encoders.destinations)\n",
    "\n",
    "        df_.Destination = df_.Destination.replace('Delhi','New Delhi')\n",
    "\n",
    "        # Applying Label encoding in destination column\n",
    "        df_['Destination label'] = df_.Destination.map(destinations)\n",
    "\n",
    "        # Dropping unncessary columns\n",
    "        df_ = df_.drop(['Source','Destination','Additional_Info'],axis=1)\n",
    "\n",
    "        stops_labels = {'non-stop':0,'1 stop':1,'2 stops':2,'3 stops':3,'4 stops':4}\n",
    "\n",
    "        # Applying label encoding in total_stops column\n",
    "        df_['Total_Stops_label'] = df_['Total_Stops'].map(stops_labels)\n",
    "\n",
    "        df_['Total_Stops_label'] = df_['Total_Stops_label'].astype('int')\n",
    "\n",
    "        df_ = df_.drop('Total_Stops',axis=1)\n",
    "\n",
    "        df_ = df_.drop('Route',axis=1)\n",
    "\n",
    "        df_ = df_.drop('Journey_year',axis=1)   # only 2019 year exists\n",
    "\n",
    "        # changing float values to int\n",
    "        for col in df_.columns:\n",
    "            if df_[col].dtype == 'float64':\n",
    "                df_[col]= df_[col].astype('int')\n",
    "\n",
    "        # Removing outliers\n",
    "\n",
    "        #Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "\n",
    "        Q1 = df_['Price'].quantile(0.25)\n",
    "        Q3 = df_['Price'].quantile(0.75)\n",
    "\n",
    "        # Calculate IQR\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Define outlier bounds\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Identify outliers\n",
    "        outliers = df_[(df_['Price'] < lower_bound) | (df_['Price'] > upper_bound)]\n",
    "\n",
    "\n",
    "        #Replacing outliers with median value\n",
    "\n",
    "        df_['Price'] = np.where(df_['Price']>upper_bound,df_['Price'].median(),df_['Price'])\n",
    "\n",
    "\n",
    "        return df_\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def train_test_spliting(self,data):\n",
    "        \n",
    "        train,test = train_test_split(data)\n",
    "\n",
    "        train.to_csv(os.path.join(self.config.root_dir,'train.csv'),index=False)\n",
    "        test.to_csv(os.path.join(self.config.root_dir,'test.csv'),index=False)\n",
    "\n",
    "        logger.info(\"Splitted data into training and test sets\")\n",
    "        logger.info(train.shape)\n",
    "        logger.info(test.shape)\n",
    "\n",
    "        print(train.shape)\n",
    "        print(test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-14 01:40:19,223: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-07-14 01:40:19,223: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-07-14 01:40:19,247: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-07-14 01:40:19,264: INFO: common: yaml file: label_encoding.yaml loaded successfully]\n",
      "[2024-07-14 01:40:19,268: INFO: common: created directory at: artifacts]\n",
      "[2024-07-14 01:40:19,271: INFO: common: created directory at: artifacts/data_transformation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rithi\\AppData\\Local\\Temp\\ipykernel_25188\\3834836195.py:13: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_.Date_of_Journey = pd.to_datetime(df_.Date_of_Journey)\n",
      "C:\\Users\\rithi\\AppData\\Local\\Temp\\ipykernel_25188\\3834836195.py:20: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_.Dep_Time = pd.to_datetime(df_.Dep_Time)\n",
      "C:\\Users\\rithi\\AppData\\Local\\Temp\\ipykernel_25188\\3834836195.py:23: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_.Arrival_Time = pd.to_datetime(df_.Arrival_Time)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-14 01:40:26,107: INFO: 3834836195: Splitted data into training and test sets]\n",
      "[2024-07-14 01:40:26,110: INFO: 3834836195: (8011, 18)]\n",
      "[2024-07-14 01:40:26,113: INFO: 3834836195: (2671, 18)]\n",
      "(8011, 18)\n",
      "(2671, 18)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data =  data_transformation.data_transformation()\n",
    "    data_transformation.train_test_spliting(data)\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
